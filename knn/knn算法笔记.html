<!DOCTYPE html><html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1"><style>body {
  max-width: 980px;
  border: 1px solid #ddd;
  outline: 1300px solid #fff;
  margin: 16px auto;
}

body .markdown-body
{
  padding: 45px;
}

@font-face {
  font-family: fontawesome-mini;
  src: url(data:font/woff;charset=utf-8;base64,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) format('woff');
}

.markdown-body {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
  color: #333333;
  overflow: hidden;
  font-family: "Helvetica Neue", Helvetica, "Segoe UI", Arial, freesans, sans-serif;
  font-size: 16px;
  line-height: 1.6;
  word-wrap: break-word;
}

.markdown-body a {
  background: transparent;
}

.markdown-body a:active,
.markdown-body a:hover {
  outline: 0;
}

.markdown-body b,
.markdown-body strong {
  font-weight: bold;
}

.markdown-body mark {
  background: #ff0;
  color: #000;
  font-style: italic;
  font-weight: bold;
}

.markdown-body sub,
.markdown-body sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
.markdown-body sup {
  top: -0.5em;
}
.markdown-body sub {
  bottom: -0.25em;
}

.markdown-body h1 {
  font-size: 2em;
  margin: 0.67em 0;
}

.markdown-body img {
  border: 0;
}

.markdown-body hr {
  -moz-box-sizing: content-box;
  box-sizing: content-box;
  height: 0;
}

.markdown-body pre {
  overflow: auto;
}

.markdown-body code,
.markdown-body kbd,
.markdown-body pre,
.markdown-body samp {
  font-family: monospace, monospace;
  font-size: 1em;
}

.markdown-body input {
  color: inherit;
  font: inherit;
  margin: 0;
}

.markdown-body html input[disabled] {
  cursor: default;
}

.markdown-body input {
  line-height: normal;
}

.markdown-body input[type="checkbox"] {
  box-sizing: border-box;
  padding: 0;
}

.markdown-body table {
  border-collapse: collapse;
  border-spacing: 0;
}

.markdown-body td,
.markdown-body th {
  padding: 0;
}

.markdown-body .codehilitetable {
  border: 0;
  border-spacing: 0;
}

.markdown-body .codehilitetable tr {
  border: 0;
}

.markdown-body .codehilitetable pre,
.markdown-body .codehilitetable div.codehilite {
  margin: 0;
}

.markdown-body .linenos,
.markdown-body .code,
.markdown-body .codehilitetable td {
  border: 0;
  padding: 0;
}

.markdown-body td:not(.linenos) .linenodiv {
  padding: 0 !important;
}

.markdown-body .code {
  width: 100%;
}

.markdown-body .linenos div pre,
.markdown-body .linenodiv pre,
.markdown-body .linenodiv {
  border: 0;
  -webkit-border-radius: 0;
  -moz-border-radius: 0;
  border-radius: 0;
  -webkit-border-top-left-radius: 3px;
  -webkit-border-bottom-left-radius: 3px;
  -moz-border-radius-topleft: 3px;
  -moz-border-radius-bottomleft: 3px;
  border-top-left-radius: 3px;
  border-bottom-left-radius: 3px;
}

.markdown-body .code div pre,
.markdown-body .code div {
  border: 0;
  -webkit-border-radius: 0;
  -moz-border-radius: 0;
  border-radius: 0;
  -webkit-border-top-right-radius: 3px;
  -webkit-border-bottom-right-radius: 3px;
  -moz-border-radius-topright: 3px;
  -moz-border-radius-bottomright: 3px;
  border-top-right-radius: 3px;
  border-bottom-right-radius: 3px;
}

.markdown-body * {
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}

.markdown-body input {
  font: 13px Helvetica, arial, freesans, clean, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol";
  line-height: 1.4;
}

.markdown-body a {
  color: #4183c4;
  text-decoration: none;
}

.markdown-body a:hover,
.markdown-body a:focus,
.markdown-body a:active {
  text-decoration: underline;
}

.markdown-body hr {
  height: 0;
  margin: 15px 0;
  overflow: hidden;
  background: transparent;
  border: 0;
  border-bottom: 1px solid #ddd;
}

.markdown-body hr:before,
.markdown-body hr:after {
  display: table;
  content: " ";
}

.markdown-body hr:after {
  clear: both;
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
  margin-top: 15px;
  margin-bottom: 15px;
  line-height: 1.1;
}

.markdown-body h1 {
  font-size: 30px;
}

.markdown-body h2 {
  font-size: 21px;
}

.markdown-body h3 {
  font-size: 16px;
}

.markdown-body h4 {
  font-size: 14px;
}

.markdown-body h5 {
  font-size: 12px;
}

.markdown-body h6 {
  font-size: 11px;
}

.markdown-body blockquote {
  margin: 0;
}

.markdown-body ul,
.markdown-body ol {
  padding: 0;
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body ol ol,
.markdown-body ul ol {
  list-style-type: lower-roman;
}

.markdown-body ul ul ol,
.markdown-body ul ol ol,
.markdown-body ol ul ol,
.markdown-body ol ol ol {
  list-style-type: lower-alpha;
}

.markdown-body dd {
  margin-left: 0;
}

.markdown-body code,
.markdown-body pre,
.markdown-body samp {
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  font-size: 12px;
}

.markdown-body pre {
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body kbd {
  background-color: #e7e7e7;
  background-image: -moz-linear-gradient(#fefefe, #e7e7e7);
  background-image: -webkit-linear-gradient(#fefefe, #e7e7e7);
  background-image: linear-gradient(#fefefe, #e7e7e7);
  background-repeat: repeat-x;
  border-radius: 2px;
  border: 1px solid #cfcfcf;
  color: #000;
  padding: 3px 5px;
  line-height: 10px;
  font: 11px Consolas, "Liberation Mono", Menlo, Courier, monospace;
  display: inline-block;
}

.markdown-body>*:first-child {
  margin-top: 0 !important;
}

.markdown-body>*:last-child {
  margin-bottom: 0 !important;
}

.markdown-body .headerlink {
  font: normal 400 16px fontawesome-mini;
  vertical-align: middle;
  margin-left: -16px;
  float: left;
  display: inline-block;
  text-decoration: none;
  opacity: 0;
  color: #333;
}

.markdown-body .headerlink:focus {
  outline: none;
}

.markdown-body h1 .headerlink {
  margin-top: 0.8rem;
}

.markdown-body h2 .headerlink,
.markdown-body h3 .headerlink {
  margin-top: 0.6rem;
}

.markdown-body h4 .headerlink {
  margin-top: 0.2rem;
}

.markdown-body h5 .headerlink,
.markdown-body h6 .headerlink {
  margin-top: 0;
}

.markdown-body .headerlink:hover,
.markdown-body h1:hover .headerlink,
.markdown-body h2:hover .headerlink,
.markdown-body h3:hover .headerlink,
.markdown-body h4:hover .headerlink,
.markdown-body h5:hover .headerlink,
.markdown-body h6:hover .headerlink {
  opacity: 1;
  text-decoration: none;
}

.markdown-body h1 {
  padding-bottom: 0.3em;
  font-size: 2.25em;
  line-height: 1.2;
  border-bottom: 1px solid #eee;
}

.markdown-body h2 {
  padding-bottom: 0.3em;
  font-size: 1.75em;
  line-height: 1.225;
  border-bottom: 1px solid #eee;
}

.markdown-body h3 {
  font-size: 1.5em;
  line-height: 1.43;
}

.markdown-body h4 {
  font-size: 1.25em;
}

.markdown-body h5 {
  font-size: 1em;
}

.markdown-body h6 {
  font-size: 1em;
  color: #777;
}

.markdown-body p,
.markdown-body blockquote,
.markdown-body ul,
.markdown-body ol,
.markdown-body dl,
.markdown-body table,
.markdown-body pre,
.markdown-body .admonition {
  margin-top: 0;
  margin-bottom: 16px;
}

.markdown-body hr {
  height: 4px;
  padding: 0;
  margin: 16px 0;
  background-color: #e7e7e7;
  border: 0 none;
}

.markdown-body ul,
.markdown-body ol {
  padding-left: 2em;
}

.markdown-body ul ul,
.markdown-body ul ol,
.markdown-body ol ol,
.markdown-body ol ul {
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body li>p {
  margin-top: 16px;
}

.markdown-body dl {
  padding: 0;
}

.markdown-body dl dt {
  padding: 0;
  margin-top: 16px;
  font-size: 1em;
  font-style: italic;
  font-weight: bold;
}

.markdown-body dl dd {
  padding: 0 16px;
  margin-bottom: 16px;
}

.markdown-body blockquote {
  padding: 0 15px;
  color: #777;
  border-left: 4px solid #ddd;
}

.markdown-body blockquote>:first-child {
  margin-top: 0;
}

.markdown-body blockquote>:last-child {
  margin-bottom: 0;
}

.markdown-body table {
  display: block;
  width: 100%;
  overflow: auto;
  word-break: normal;
  word-break: keep-all;
}

.markdown-body table th {
  font-weight: bold;
}

.markdown-body table th,
.markdown-body table td {
  padding: 6px 13px;
  border: 1px solid #ddd;
}

.markdown-body table tr {
  background-color: #fff;
  border-top: 1px solid #ccc;
}

.markdown-body table tr:nth-child(2n) {
  background-color: #f8f8f8;
}

.markdown-body img {
  max-width: 100%;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}

.markdown-body code,
.markdown-body samp {
  padding: 0;
  padding-top: 0.2em;
  padding-bottom: 0.2em;
  margin: 0;
  font-size: 85%;
  background-color: rgba(0,0,0,0.04);
  border-radius: 3px;
}

.markdown-body code:before,
.markdown-body code:after {
  letter-spacing: -0.2em;
  content: "\00a0";
}

.markdown-body pre>code {
  padding: 0;
  margin: 0;
  font-size: 100%;
  word-break: normal;
  white-space: pre;
  background: transparent;
  border: 0;
}

.markdown-body .codehilite {
  margin-bottom: 16px;
}

.markdown-body .codehilite pre,
.markdown-body pre {
  padding: 16px;
  overflow: auto;
  font-size: 85%;
  line-height: 1.45;
  background-color: #f7f7f7;
  border-radius: 3px;
}

.markdown-body .codehilite pre {
  margin-bottom: 0;
  word-break: normal;
}

.markdown-body pre {
  word-wrap: normal;
}

.markdown-body pre code {
  display: inline;
  max-width: initial;
  padding: 0;
  margin: 0;
  overflow: initial;
  line-height: inherit;
  word-wrap: normal;
  background-color: transparent;
  border: 0;
}

.markdown-body pre code:before,
.markdown-body pre code:after {
  content: normal;
}

/* Admonition */
.markdown-body .admonition {
  -webkit-border-radius: 3px;
  -moz-border-radius: 3px;
  position: relative;
  border-radius: 3px;
  border: 1px solid #e0e0e0;
  border-left: 6px solid #333;
  padding: 10px 10px 10px 30px;
}

.markdown-body .admonition table {
  color: #333;
}

.markdown-body .admonition p {
  padding: 0;
}

.markdown-body .admonition-title {
  font-weight: bold;
  margin: 0;
}

.markdown-body .admonition>.admonition-title {
  color: #333;
}

.markdown-body .attention>.admonition-title {
  color: #a6d796;
}

.markdown-body .caution>.admonition-title {
  color: #d7a796;
}

.markdown-body .hint>.admonition-title {
  color: #96c6d7;
}

.markdown-body .danger>.admonition-title {
  color: #c25f77;
}

.markdown-body .question>.admonition-title {
  color: #96a6d7;
}

.markdown-body .note>.admonition-title {
  color: #d7c896;
}

.markdown-body .admonition:before,
.markdown-body .attention:before,
.markdown-body .caution:before,
.markdown-body .hint:before,
.markdown-body .danger:before,
.markdown-body .question:before,
.markdown-body .note:before {
  font: normal normal 16px fontawesome-mini;
  -moz-osx-font-smoothing: grayscale;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  line-height: 1.5;
  color: #333;
  position: absolute;
  left: 0;
  top: 0;
  padding-top: 10px;
  padding-left: 10px;
}

.markdown-body .admonition:before {
  content: "\f056\00a0";
  color: 333;
}

.markdown-body .attention:before {
  content: "\f058\00a0";
  color: #a6d796;
}

.markdown-body .caution:before {
  content: "\f06a\00a0";
  color: #d7a796;
}

.markdown-body .hint:before {
  content: "\f05a\00a0";
  color: #96c6d7;
}

.markdown-body .danger:before {
  content: "\f057\00a0";
  color: #c25f77;
}

.markdown-body .question:before {
  content: "\f059\00a0";
  color: #96a6d7;
}

.markdown-body .note:before {
  content: "\f040\00a0";
  color: #d7c896;
}

.markdown-body .admonition::after {
  content: normal;
}

.markdown-body .attention {
  border-left: 6px solid #a6d796;
}

.markdown-body .caution {
  border-left: 6px solid #d7a796;
}

.markdown-body .hint {
  border-left: 6px solid #96c6d7;
}

.markdown-body .danger {
  border-left: 6px solid #c25f77;
}

.markdown-body .question {
  border-left: 6px solid #96a6d7;
}

.markdown-body .note {
  border-left: 6px solid #d7c896;
}

.markdown-body .admonition>*:first-child {
  margin-top: 0 !important;
}

.markdown-body .admonition>*:last-child {
  margin-bottom: 0 !important;
}

/* progress bar*/
.markdown-body .progress {
  display: block;
  width: 300px;
  margin: 10px 0;
  height: 24px;
  -webkit-border-radius: 3px;
  -moz-border-radius: 3px;
  border-radius: 3px;
  background-color: #ededed;
  position: relative;
  box-shadow: inset -1px 1px 3px rgba(0, 0, 0, .1);
}

.markdown-body .progress-label {
  position: absolute;
  text-align: center;
  font-weight: bold;
  width: 100%; margin: 0;
  line-height: 24px;
  color: #333;
  text-shadow: 1px 1px 0 #fefefe, -1px -1px 0 #fefefe, -1px 1px 0 #fefefe, 1px -1px 0 #fefefe, 0 1px 0 #fefefe, 0 -1px 0 #fefefe, 1px 0 0 #fefefe, -1px 0 0 #fefefe, 1px 1px 2px #000;
  -webkit-font-smoothing: antialiased !important;
  white-space: nowrap;
  overflow: hidden;
}

.markdown-body .progress-bar {
  height: 24px;
  float: left;
  -webkit-border-radius: 3px;
  -moz-border-radius: 3px;
  border-radius: 3px;
  background-color: #96c6d7;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, .5), inset 0 -1px 0 rgba(0, 0, 0, .1);
  background-size: 30px 30px;
  background-image: -webkit-linear-gradient(
    135deg, rgba(255, 255, 255, .4) 27%,
    transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%,
    transparent 77%, transparent
  );
  background-image: -moz-linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
  background-image: -ms-linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
  background-image: -o-linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
  background-image: linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
}

.markdown-body .progress-100plus .progress-bar {
  background-color: #a6d796;
}

.markdown-body .progress-80plus .progress-bar {
  background-color: #c6d796;
}

.markdown-body .progress-60plus .progress-bar {
  background-color: #d7c896;
}

.markdown-body .progress-40plus .progress-bar {
  background-color: #d7a796;
}

.markdown-body .progress-20plus .progress-bar {
  background-color: #d796a6;
}

.markdown-body .progress-0plus .progress-bar {
  background-color: #c25f77;
}

.markdown-body .candystripe-animate .progress-bar{
  -webkit-animation: animate-stripes 3s linear infinite;
  -moz-animation: animate-stripes 3s linear infinite;
  animation: animate-stripes 3s linear infinite;
}

@-webkit-keyframes animate-stripes {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 60px 0;
  }
}

@-moz-keyframes animate-stripes {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 60px 0;
  }
}

@keyframes animate-stripes {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 60px 0;
  }
}

.markdown-body .gloss .progress-bar {
  box-shadow:
    inset 0 4px 12px rgba(255, 255, 255, .7),
    inset 0 -12px 0 rgba(0, 0, 0, .05);
}

/* Multimarkdown Critic Blocks */
.markdown-body .critic_mark {
  background: #ff0;
}

.markdown-body .critic_delete {
  color: #c82829;
  text-decoration: line-through;
}

.markdown-body .critic_insert {
  color: #718c00 ;
  text-decoration: underline;
}

.markdown-body .critic_comment {
  color: #8e908c;
  font-style: italic;
}

.markdown-body .headeranchor {
  font: normal normal 16px fontawesome-mini;
  line-height: 1;
  display: inline-block;
  text-decoration: none;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.headeranchor:before {
  content: '\e157';
}

.markdown-body .task-list-item {
  list-style-type: none;
}

.markdown-body .task-list-item+.task-list-item {
  margin-top: 3px;
}

.markdown-body .task-list-item input {
  margin: 0 4px 0.25em -20px;
  vertical-align: middle;
}

/* Media */
@media only screen and (min-width: 480px) {
  .markdown-body {
    font-size:14px;
  }
}

@media only screen and (min-width: 768px) {
  .markdown-body {
    font-size:16px;
  }
}

@media print {
  .markdown-body * {
    background: transparent !important;
    color: black !important;
    filter:none !important;
    -ms-filter: none !important;
  }

  .markdown-body {
    font-size:12pt;
    max-width:100%;
    outline:none;
    border: 0;
  }

  .markdown-body a,
  .markdown-body a:visited {
    text-decoration: underline;
  }

  .markdown-body .headeranchor-link {
    display: none;
  }

  .markdown-body a[href]:after {
    content: " (" attr(href) ")";
  }

  .markdown-body abbr[title]:after {
    content: " (" attr(title) ")";
  }

  .markdown-body .ir a:after,
  .markdown-body a[href^="javascript:"]:after,
  .markdown-body a[href^="#"]:after {
    content: "";
  }

  .markdown-body pre {
    white-space: pre;
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .markdown-body pre,
  .markdown-body blockquote {
    border: 1px solid #999;
    padding-right: 1em;
    page-break-inside: avoid;
  }

  .markdown-body .progress,
  .markdown-body .progress-bar {
    -moz-box-shadow: none;
    -webkit-box-shadow: none;
    box-shadow: none;
  }

  .markdown-body .progress {
    border: 1px solid #ddd;
  }

  .markdown-body .progress-bar {
    height: 22px;
    border-right: 1px solid #ddd;
  }

  .markdown-body tr,
  .markdown-body img {
    page-break-inside: avoid;
  }

  .markdown-body img {
    max-width: 100% !important;
  }

  .markdown-body p,
  .markdown-body h2,
  .markdown-body h3 {
    orphans: 3;
    widows: 3;
  }

  .markdown-body h2,
  .markdown-body h3 {
    page-break-after: avoid;
  }
}
</style><style>/*github*/
.codehilite {background-color:#fff;color:#333333;}
.codehilite .hll {background-color:#ffffcc;}
.codehilite .c{color:#999988;font-style:italic}
.codehilite .err{color:#a61717;background-color:#e3d2d2}
.codehilite .k{font-weight:bold}
.codehilite .o{font-weight:bold}
.codehilite .cm{color:#999988;font-style:italic}
.codehilite .cp{color:#999999;font-weight:bold}
.codehilite .c1{color:#999988;font-style:italic}
.codehilite .cs{color:#999999;font-weight:bold;font-style:italic}
.codehilite .gd{color:#000000;background-color:#ffdddd}
.codehilite .ge{font-style:italic}
.codehilite .gr{color:#aa0000}
.codehilite .gh{color:#999999}
.codehilite .gi{color:#000000;background-color:#ddffdd}
.codehilite .go{color:#888888}
.codehilite .gp{color:#555555}
.codehilite .gs{font-weight:bold}
.codehilite .gu{color:#800080;font-weight:bold}
.codehilite .gt{color:#aa0000}
.codehilite .kc{font-weight:bold}
.codehilite .kd{font-weight:bold}
.codehilite .kn{font-weight:bold}
.codehilite .kp{font-weight:bold}
.codehilite .kr{font-weight:bold}
.codehilite .kt{color:#445588;font-weight:bold}
.codehilite .m{color:#009999}
.codehilite .s{color:#dd1144}
.codehilite .n{color:#333333}
.codehilite .na{color:teal}
.codehilite .nb{color:#0086b3}
.codehilite .nc{color:#445588;font-weight:bold}
.codehilite .no{color:teal}
.codehilite .ni{color:purple}
.codehilite .ne{color:#990000;font-weight:bold}
.codehilite .nf{color:#990000;font-weight:bold}
.codehilite .nn{color:#555555}
.codehilite .nt{color:navy}
.codehilite .nv{color:teal}
.codehilite .ow{font-weight:bold}
.codehilite .w{color:#bbbbbb}
.codehilite .mf{color:#009999}
.codehilite .mh{color:#009999}
.codehilite .mi{color:#009999}
.codehilite .mo{color:#009999}
.codehilite .sb{color:#dd1144}
.codehilite .sc{color:#dd1144}
.codehilite .sd{color:#dd1144}
.codehilite .s2{color:#dd1144}
.codehilite .se{color:#dd1144}
.codehilite .sh{color:#dd1144}
.codehilite .si{color:#dd1144}
.codehilite .sx{color:#dd1144}
.codehilite .sr{color:#009926}
.codehilite .s1{color:#dd1144}
.codehilite .ss{color:#990073}
.codehilite .bp{color:#999999}
.codehilite .vc{color:teal}
.codehilite .vg{color:teal}
.codehilite .vi{color:teal}
.codehilite .il{color:#009999}
.codehilite .gc{color:#999;background-color:#EAF2F5}
</style><title>knn算法笔记</title></head><body><article class="markdown-body"><h1 id="-knn">机器学习实战笔记-knn算法实战<a class="headerlink" href="#-knn" title="Permanent link"></a></h1>
<blockquote>
<p>本文内容源于《机器学习实战》一书，主要介绍了knn(k-nearest neighbor)算法的原理、python代码实现、以及两个简单的应用案例。</p>
</blockquote>
<div class="toc">
<ul>
<li><a href="#-knn">机器学习实战笔记-knn算法实战</a></li>
<li><a href="#_1">一般步骤</a></li>
<li><a href="#_2">需要掌握的知识</a></li>
<li><a href="#knnk-nearest-neighbor">knn(k-nearest neighbor)算法</a><ul>
<li><a href="#k-">k-最近邻算法核心代码</a></li>
</ul>
</li>
<li><a href="#-1">练习题-1</a><ul>
<li><a href="#_3">数据准备</a></li>
<li><a href="#_4">分析数据</a></li>
<li><a href="#_5">测试分类器</a><ul>
<li><a href="#_6">用错误率来衡量分类结果</a></li>
<li><a href="#_7">分类器测试结果</a></li>
</ul>
</li>
<li><a href="#_8">使用算法</a></li>
<li><a href="#_9">最终的约会决策模型</a></li>
<li><a href="#_10">代码整合</a></li>
</ul>
</li>
<li><a href="#-2">练习题-2</a><ul>
<li><a href="#_11">准备数据</a></li>
<li><a href="#_12">手写识别模型代码汇总</a></li>
</ul>
</li>
<li><a href="#sklearn">尝试用sklearn来分类</a><ul>
<li><a href="#knn-kd">knn算法实现&ndash;&gt;kd树</a><ul>
<li><a href="#kd">构造kd树</a></li>
<li><a href="#kd_1">搜索kd树</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_13">小结</a></li>
<li><a href="#_14">推荐阅读</a></li>
</ul>
</div>
<h1 id="_1">一般步骤<a class="headerlink" href="#_1" title="Permanent link"></a></h1>
<blockquote>
<p>机器学习一般流程如下，主要包括从数据获取到预处理，到分析数据筛选特征最后到模型训练、选择、评估、使用的过程。</p>
</blockquote>
<p>1.收集数据
2.输入数据(字符型、数值型)
3.分析数据(空置、异常值、缺失值.....垃圾数据)
4.训练算法
5.测试算法，5&mdash;&gt;4/1，根据测试结果返回4或者1继续。
6.使用算法</p>
<hr />
<h1 id="_2">需要掌握的知识<a class="headerlink" href="#_2" title="Permanent link"></a></h1>
<ul>
<li><strong>Numpy基础</strong>
需要用到<code>numpy</code>的一些基础，这部分内容对自己用代码实现算法帮助很大。涉及到<code>&lt;数组，矩阵，计算&gt;</code>等操作，需要用到什么可以学习或者检索相关的api。</li>
<li><strong>matplotlib基础</strong>
这个库是python中涉及到图形绘制，可以展现数据的规律。</li>
<li>基本的算法及数学知识，包括&lt;高数、线性代数、概率论&gt;知识。</li>
</ul>
<hr />
<h1 id="knnk-nearest-neighbor">knn(k-nearest neighbor)算法<a class="headerlink" href="#knnk-nearest-neighbor" title="Permanent link"></a></h1>
<blockquote>
<p>用于测量不同特征值之间的距离进行分类。</p>
</blockquote>
<ul>
<li>优点：精度高、<code>异常值不敏感、无数据输入假定</code></li>
<li>缺点：计算复杂、<code>空间复杂</code></li>
<li>适用数据:数值型、标签型</li>
</ul>
<blockquote>
<p>算法原理：在已经有分类标签的数据集中，输入无标签的新数据，计算新数据特征和训练集特征的距离，选择排名前k个最近的距离，统计这些属于哪个类别。</p>
</blockquote>
<ul>
<li><strong>伪代码：</strong><ul>
<li>计算未知点和数据集中已知点的距离</li>
<li>按距离递增排序</li>
<li>选取与当前点距离最小的k个点</li>
<li>计算类别频率</li>
<li>返回频率最高的类别作为分类结果</li>
</ul>
</li>
</ul>
<hr />
<h2 id="k-">k-最近邻算法核心代码<a class="headerlink" href="#k-" title="Permanent link"></a></h2>
<p><div class="codehilite"><pre>&#39;&#39;&#39;
knn
inX:测试集
dataSet:训练集
labels:标签
K:选取前K个值
&#39;&#39;&#39;
def classify0(inX,dataSet,labels,k):
    dataSetSize = dataSet.shape[0]
    diffMat = tile(inX,(dataSetSize,1)) - dataSet
    #tile用于把inX横向或者纵向复制，即把inX扩充成于dataSet相同维度。

    sqDiffMat = diffMat**2
    sqDistances = sqDiffMat.sum(axis = 1)
    distances = sqDistances**0.5
    sorteDistIndicies = distances.argsort()
    #计算距离，新数据每个点和训练集的距离;
    #argsort(),排序并返回原数组索引.
    #[8,2,1,4,5,7]---&gt;index[0:k]----&gt;取k个索引

    classCount = {}
    for i in range(k):
        voteIlabel = labels[sorteDistIndicies[I]]
        classCount[voteIlabel] = classCount.get(voteIlabel,0)+1
        #遍历，排序后前k个索引，labels[index]---&gt;类别
        #字典get方法，统计类别次数，没有返回0，次数+1
    sortedClassCount = sorted(classCount.items(),
        key = operator.itemgetter(1),reverse =True)
    return sortedClassCount[0][0]
</pre></div>
对于上述代码，其实可以拆解成以下2部分更容易理解：
* 首先是计算距离 
* 其次是统计k范围内类别个数</p>
<p><strong>关于距离的计算,其实距离的选择有很多种，因此产生了许多对knn算法的改进版本：比如距离加权knn等</strong></p>
<hr />
<p>自己将书上的代码拆成2块便于理解，有一点小区别在于：对<code>字典按值进行排序</code>，例子用了operator.itemgetter()方法，自己用了字典的<code>items()</code>方法.</p>
<blockquote>
<p><strong>代码中的技巧和思路：</strong>1.数组排序后返回索引&ndash;<code>array.argsort()</code>方法；2.统计某一类别出现的次数，巧妙用了<code>字典的get()</code>方法。</p>
</blockquote>
<div class="codehilite"><pre>&#39;&#39;&#39;
knn:
1.计算距离
2.升序排序，选k值
3.计算类别概率
&#39;&#39;&#39;
#计算测试数据和训练集所有点的距离，返回排序后的索引
def CountDistance(sample,d_train):
    Size = d_train.shape[0]
    diffMat = tile(sample,(Size,1)) - d_train
    sqDiffMat = diffMat**2
    sqDistances = sqDiffMat.sum(axis=1)
    distances = sqDistances**0.5
    dist_index = distances.argsort()
    return dist_index

#统计类别，返回前k个距离最多的类别
classCount ={}
def LabelCount(dist_index,k,labels):
    for i in range(k):
        kind = labels[dist_index[I]]

    ‘’‘
    思路很优秀，利用字典的get方法，来统计相应类别在前k个距离中出现的次数，得到类似的结果{&#39;A&#39;:10,&#39;B&#39;:3}，然后根据字典的值进行降序排序，即可得到结果。

    ’‘’
        classCount[kind] = classCount.get(kind,0)+1
    result = sorted(classCount.items(),key = lambda x:x[1],reverse=True)
    return result[0][0]

#函数整合在一起
def knn(sample,d_train,k,labels):
    dist_index = CountDistance(sample,d_train)
    result = LabelCount(dist_index,k,labels)
    return result
</pre></div>

<blockquote>
<p>__小结：__这个是python实现的最基础的knn核心代码，主体思想就是<code>距离计算</code>和<code>统计标签类别</code>。</p>
</blockquote>
<hr />
<h1 id="-1">练习题-1<a class="headerlink" href="#-1" title="Permanent link"></a></h1>
<p><strong>海伦约会对象分类案例</strong>
按照1-6的步骤进行，需要进行测试</p>
<h2 id="_3">数据准备<a class="headerlink" href="#_3" title="Permanent link"></a></h2>
<p>将txt文件，按行读取，转化成数组(因为元素可以是字符串和数)；不必按照书上做，太繁琐，先根据文件行数设置空矩阵，然后往里填数字。
<div class="codehilite"><pre>import numpy as np

filename = &#39;datingTestSet.txt&#39;
path = &#39;/Users/tony/github/machine-learning-in-action/k-Nearest Neighbor/&#39;+filename

def load_txt(filename):
    f = open(filename,&#39;r&#39;)
    mid= f.readlines()
    mid2 = [x.strip(&#39;\n&#39;).split(&#39;\t&#39;) for x in mid]
    arr = np.array(mid2)
    labels = arr[:,3]
    groups = arr[:,0:3]
    return groups,labels
</pre></div></p>
<h2 id="_4">分析数据<a class="headerlink" href="#_4" title="Permanent link"></a></h2>
<p>拿到数据首先要对数据进行观察，由于只有3个特征，可以做散点图来查看特征之间的关系。需要用到matplotlib绘图功能。
<div class="codehilite"><pre>import matplotlib.pyplot as plt

def plot(dt,labels):
    plt.figure()
    a1 = np.char.replace(labels,&#39;largeDoses&#39;,&#39;r&#39;)
    a2 = np.char.replace(a1,&#39;didntLike&#39;,&#39;b&#39;)
    a3 = np.char.replace(a2,&#39;smallDoses&#39;,&#39;g&#39;)
    c = a3
    plt.scatter(dt[:,0],dt[:,1],c=a3,marker=&#39;o&#39;,alpha=0.5)
    plt.xlabel(&#39;pilot distance&#39;)
    plt.ylabel(&#39;game time&#39;)
    plt.legend(loc =2 ,)
    plt.show()
</pre></div>
<img alt="travel distance-game time的关系" src="https://upload-images.jianshu.io/upload_images/14359324-e1535b38cbbc2463.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" />
关于三类对象的游戏时间和旅行距离的散点图，通过将三类人的类别标签映射到图像上，可以使得数据更为明显。说明海伦在意的对象类型和游戏时间以及旅行距离有明显的联系。</p>
<blockquote>
<p>观察数据可以发现，旅行距离的数值要远大于游戏和冰淇淋的值，为了避免这个值太大而对另外两个特征造成影响，需要进行数据的归一化处理。</p>
</blockquote>
<p><strong>归一化数值:0-1归一化,<code>new = (old - min) / (max - min)</code></strong>
* 使用现成的<code>sklearn</code>包更为便捷
因为已经得到现成的特征向量，所以直接归一化就行了
* 虽然也可以写一个函数来实现归一化，但是效率不高。</p>
<hr />
<h2 id="_5">测试分类器<a class="headerlink" href="#_5" title="Permanent link"></a></h2>
<h4 id="_6">用错误率来衡量分类结果<a class="headerlink" href="#_6" title="Permanent link"></a></h4>
<ul>
<li>涉及到训练集和测试集的划分：<ul>
<li>关于数据划分，可以直接用sklearn的<code>train_test_split</code>,在<code>model_selection</code>下。<strong>(但这样划分，缺少验证集)</strong><ul>
<li>其中<code>random_state</code>代表<code>随机种子</code>：其实就是该组随机数的编号，在需要重复试验的时候，保证得到一组一样的随机数。比如你每次都填1，其他参数一样的情况下你得到的随机数组是一样的。但填0或不填，每次都会不一样。</li>
<li>随机数的产生取决于种子，随机数和种子之间的关系遵从以下两个规则：<strong>种子不同，产生不同的随机数；种子相同，即使实例不同也产生相同的随机数。</strong></li>
</ul>
</li>
<li>每一个测试样本带入分类器，查看分类结果，判断并记录下对错</li>
<li>可以使用交叉验证和留出法对数据进行划分。</li>
</ul>
</li>
</ul>
<hr />
<h4 id="_7">分类器测试结果<a class="headerlink" href="#_7" title="Permanent link"></a></h4>
<ul>
<li>以下是用于测试分类结果的函数，输出为分类错误率。</li>
</ul>
<hr />
<blockquote>
<p>这个结果仅对于<code>一次样本划分</code>的数据集而言，而且<code>k值</code>选择仅为1次，所以这个函数里面的参数可以进一步改变，
<code>&lt;调参&gt;</code>，来查看不同数据划分和k值选择情况下分类结果是怎么样的。</p>
</blockquote>
<p><div class="codehilite"><pre>from sklearn import preprocessing
from sklearn.model_selection import train_test_split

def datingTest(X_test,X_train,y_train,test_size,k):
    &#39;&#39;&#39;
    knn测试
    test_size:测试集大小
    k:距离升序排序的前k个值
    ...
    剩下的是划分的数据集
    output:分类错误率
    &#39;&#39;&#39;
    error_rate = {&#39;true&#39;:0,&#39;false&#39;:0}
    y_predict = []
    for i in range(test_size):
        result = classify0(X_test[i],X_train,y_train,20)
        y_predict.append(result)
        print(&#39;the classify result is : %s , the real answer is : %s&#39;%(result,y_test[I]))
        if result==y_test[I]:
            error_rate[&#39;true&#39;] += 1
        else:
            error_rate[&#39;false&#39;] += 1
    er_rate = error_rate[&#39;false&#39;]/100
    return er_rate
</pre></div>
<img alt="测试分类器结果" src="https://upload-images.jianshu.io/upload_images/14359324-3c224816d5bc123b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<p><strong>当k选择20时，分类错误率为0.2，可以接受，说明分类效果良好。(当然，书上效果比较粗略，未考虑到数据集划分方式以及不同k值选取对分类结果的影响。)</strong></p>
<hr />
<h2 id="_8">使用算法<a class="headerlink" href="#_8" title="Permanent link"></a></h2>
<p>对于分类效果良好的模型，可以直接拿来使用。</p>
<hr />
<p>关于判断约会对象的小程序基本功能和用法如下：
    * 根据输入的3条属性，来给出这个人是否值得约会
    * 在输入测试数据时，记得要对其进行<code>归一化</code></p>
<hr />
<h2 id="_9">最终的约会决策模型<a class="headerlink" href="#_9" title="Permanent link"></a></h2>
<p><div class="codehilite"><pre>def personDecision():
    ice =float(input(&#39;ice cream consumed per year:&#39;))
    travel = float(input(&#39;travel distance per year:&#39;))
    game = float(input(&#39;game time per year:&#39;))
    person = np.array([travel,game,ice]).reshape(1,-1)
    #需要归一化
    person_norm = preprocessing.normalize(person, norm=&#39;l2&#39;)
    decision = classify0(person_norm,X_train,y_train,20)
    print(&#39;You might have %s with this guy.&#39;%decision)
    return 
</pre></div>
<img alt="模型分类结果" src="https://upload-images.jianshu.io/upload_images/14359324-ebe73658426cf25d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h2 id="_10">代码整合<a class="headerlink" href="#_10" title="Permanent link"></a></h2>
<p>将上述步骤代码整合如下：
<div class="codehilite"><pre>import numpy as np
from numpy import *
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
import operator

def classify0(inX,dataSet,labels,k):

    &#39;&#39;&#39;
    knn分类器
    -----------
    inX:测试样本
    dataSet:训练集
    labels:训练标签
    k:距离最近的前k个值
    &#39;&#39;&#39;
    dataSetSize = dataSet.shape[0]
    diffMat = tile(inX,(dataSetSize,1)) - dataSet
    #tile用于把inX横向或者纵向复制，即把inX扩充成于dataSet相同维度。

    sqDiffMat = diffMat**2
    sqDistances = sqDiffMat.sum(axis = 1)
    distances = sqDistances**0.5
    sorteDistIndicies = distances.argsort()
    #计算距离，新数据每个点和训练集的距离;
    #argsort(),排序并返回原数组索引.
    #[8,2,1,4,5,7]---&gt;index[0:k]----&gt;取k个索引

    classCount = {}
    for i in range(k):
        voteIlabel = labels[sorteDistIndicies[I]]
        classCount[voteIlabel] = classCount.get(voteIlabel,0)+1
        #遍历，排序后前k个索引，labels[index]---&gt;类别
        #字典get方法，统计类别次数，没有返回0，次数+1
    sortedClassCount = sorted(classCount.items(),
        key = operator.itemgetter(1),reverse =True)
    return sortedClassCount[0][0]


&#39;&#39;&#39;
最终使用的约会对象分类模型
&#39;&#39;&#39;
def personDecision():
    &#39;&#39;&#39;
    约会对象筛选模型：
    output:根据这个人的习惯:ice,travel,game，初步判断是否值得约会
    &#39;&#39;&#39;
    ice =float(input(&#39;ice cream consumed per year:&#39;))
    travel = float(input(&#39;travel distance per year:&#39;))
    game = float(input(&#39;game time per year:&#39;))
    person = np.array([travel,game,ice]).reshape(1,-1)
    #需要归一化
    person_norm = preprocessing.normalize(person, norm=&#39;l2&#39;)
    decision = classify0(person_norm,X_train,y_train,20)
    print(&#39;You might have %s with this guy.&#39;%decision)
    return 

def load_txt(filename):
    &#39;&#39;&#39;
    读取数据集
    &#39;&#39;&#39;
    f = open(filename,&#39;r&#39;)
    #按行读取，返回list
    mid= f.readlines()
    mid2 = [x.strip(&#39;\n&#39;).split(&#39;\t&#39;) for x in mid]
    arr = np.array(mid2)
    labels = arr[:,3]
    groups = np.array(arr[:,0:3],dtype=float)
    return groups,labels


if __name__ ==&#39;__main__&#39;:
    filename = &#39;datingTestSet.txt&#39;
    path = &#39;/Users/tony/github/machine-learning-in-action/k-Nearest Neighbor/&#39;+filename
    G,L = load_txt(filename)
    #归一化
    G_normalized = preprocessing.normalize(G, norm=&#39;l2&#39;)
    #划分数据集
    X_train,X_test,y_train,y_test = train_test_split(G_normalized,L,test_size = 0.1,random_state = 21)
    personDecision()    
</pre></div>
__</p>
<h1 id="-2">练习题-2<a class="headerlink" href="#-2" title="Permanent link"></a></h1>
<p><strong>手写识别系统：</strong>
* 存在图像文件，是手写字体，存储为图像的形式，需要通过knn模型，识别出每幅图像真实的数字信息。</p>
<p>步骤如练习1</p>
<h2 id="_11">准备数据<a class="headerlink" href="#_11" title="Permanent link"></a></h2>
<p>因为数据集已经有了，需要做的是将其读取到python中</p>
<p>查看数据发现，数据是以txt文件保存的，每个文件都是数字排列组成的图像，文件名是这组数据代表的数字以及这个数字的样本编号</p>
<p>需要做的是将整个文件作为一个向量存储。涉及到矩阵的向量化处理。</p>
<hr />
<p>思路是：
* 将每个文件读取成一个array
* 记录每个文件的label信息，根据文件名
* 由于已经分好了，不需要对数据集进行划分</p>
<p><img alt="手写数据" src="https://upload-images.jianshu.io/upload_images/14359324-7915d8ba530627c1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h2 id="_12">手写识别模型代码汇总<a class="headerlink" href="#_12" title="Permanent link"></a></h2>
<ul>
<li>主要包括：knn分类器</li>
<li>文件读取函数<code>read_file()</code></li>
<li>图像转数组函数<code>changeTodataSet()</code></li>
</ul>
<p><div class="codehilite"><pre>from numpy import *
import operator
import os

&#39;&#39;&#39;
手写识别模型
&#39;&#39;&#39;

def classify0(inX,dataSet,labels,k):

    &#39;&#39;&#39;
    knn分类器
    -----------
    inX:测试样本
    dataSet:训练集
    labels:训练标签
    k:距离最近的前k个值
    &#39;&#39;&#39;
    dataSetSize = dataSet.shape[0]
    diffMat = tile(inX,(dataSetSize,1)) - dataSet
    #tile用于把inX横向或者纵向复制，即把inX扩充成于dataSet相同维度。

    sqDiffMat = diffMat**2
    sqDistances = sqDiffMat.sum(axis = 1)
    distances = sqDistances**0.5
    sorteDistIndicies = distances.argsort()
    #计算距离，新数据每个点和训练集的距离;
    #argsort(),排序并返回原数组索引.
    #[8,2,1,4,5,7]---&gt;index[0:k]----&gt;取k个索引

    classCount = {}
    for i in range(k):
        voteIlabel = labels[sorteDistIndicies[I]]
        classCount[voteIlabel] = classCount.get(voteIlabel,0)+1
        #遍历，排序后前k个索引，labels[index]---&gt;类别
        #字典get方法，统计类别次数，没有返回0，次数+1
    sortedClassCount = sorted(classCount.items(),
        key = operator.itemgetter(1),reverse =True)
    return sortedClassCount[0][0]


def read_file(file,path):
    &#39;&#39;&#39;
    将图像文件读取成数组
    file:文件名
    output:该文件的数组向量
    &#39;&#39;&#39;
    PT = path+file
    with open(PT,&#39;r&#39;) as f:
        txt = f.readlines()
        mid_str = list(map(lambda x:x.strip(&#39;\n&#39;),txt))
        arr = []
        for i in range(32):
            mid_int = list(map(lambda x:int(x),mid_str[I]))
            arr.extend(mid_int)
        return array(arr)

def changeTodataSet(path):
    &#39;&#39;&#39;
    批量读取文件，成为数组，组成数据集
    &#39;&#39;&#39;
    dataList = os.listdir(path)
    labels = array(list(map(lambda x:x.split(&#39;_&#39;)[0],dataList)))
    group = array(list(map(lambda x:read_file(file = x,path=path),dataList)))
    return group,labels    

def HandwritingRecgnize():
    &#39;&#39;&#39;
    手写识别模型
    output:识别结果，错误数量，识别错误率。
    &#39;&#39;&#39;
    num = len(group_text)
    error = 0
    for i in range(num):
        predict_num = classify0(group_text[i],group_train,labels_train,20)
        real_num = labels_text[I]
        print(&#39;the predict num is : %s&#39;%predict_num,&#39;the real num is : %s&#39;%real_num)
        if predict_num !=real_num:error += 1
    print(&#39;predict error time is :%d&#39;%error)
    print(&#39;total error rate is :%f&#39;%(error/num)) 
    return

if __name__ == &#39;__main__&#39;:
    group_train,labels_train = changeTodataSet(&#39;./digits/trainingDigits/&#39;)
    group_text,labels_text = changeTodataSet(&#39;./digits/testDigits/&#39;)
    HandwritingRecgnize()
</pre></div>
<img alt="手写识别模型分类结果及错误率" src="https://upload-images.jianshu.io/upload_images/14359324-d4cdf3f7801c9059.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h1 id="sklearn">尝试用sklearn来分类<a class="headerlink" href="#sklearn" title="Permanent link"></a></h1>
<p><code>class sklearn.neighbors.KNeighborsClassifier</code>(n_neighbors=5, weights=’uniform’, algorithm=’auto’, leaf_size=30, p=2, metric=’minkowski’, metric_params=None, n_jobs=None, **kwargs)¶</p>
<p><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier">sklearn官方手册</a></p>
<p><strong>从下面的结果可以看出</strong>
* <code>KNeighborsClassifier</code>是一个knn的分类器，在设置好k值后确定分类模型
* <code>neigh.fit</code>用训练样本的数据和标签去拟合这个模型
* <code>neigh.predict</code>预测分类结果
* <code>neigh.score</code>提供测试集计算模型分类精度</p>
<p><strong>整理代码</strong>
通过调用sklearn的api可以得到更简洁的代码
<div class="codehilite"><pre>from numpy import *
import numpy as np
import operator
import os
from sklearn.neighbors import KNeighborsClassifier

def read_file(file,path):
    &#39;&#39;&#39;
    将图像文件读取成数组
    file:文件名
    output:该文件的数组向量
    &#39;&#39;&#39;
    PT = path+file
    with open(PT,&#39;r&#39;) as f:
        txt = f.readlines()
        mid_str = list(map(lambda x:x.strip(&#39;\n&#39;),txt))
        arr = []
        for i in range(32):
            mid_int = list(map(lambda x:int(x),mid_str[I]))
            arr.extend(mid_int)
        return array(arr)

def changeTodataSet(path):
    &#39;&#39;&#39;
    批量读取文件，成为数组，组成数据集
    &#39;&#39;&#39;
    dataList = os.listdir(path)
    labels = array(list(map(lambda x:x.split(&#39;_&#39;)[0],dataList)))
    group = array(list(map(lambda x:read_file(file = x,path=path),dataList)))
    return group,labels    


def sk_knn():
    &#39;&#39;&#39;
    用sklearn在做knn分类

    &#39;&#39;&#39;
    neigh = KNeighborsClassifier(n_neighbors=20)
    neigh.fit(group_train,labels_train)
    result = neigh.predict(group_text)
    accuracy = neigh.score(group_text,labels_text)
    return result,accuracy

if __name__ == &#39;__main__&#39;:
    group_train,labels_train = changeTodataSet(&#39;./digits/trainingDigits/&#39;)
    group_text,labels_text = changeTodataSet(&#39;./digits/testDigits/&#39;)
    result,accuracy = sk_knn()    
    num = len(result)
    for i in range(num):
        predict_num = result[I]
        real_num = labels_text[I]
        print(&#39;the predict num is :%s&#39;%predict_num,&#39;the real num is :%s&#39;%real_num)
    print(&#39;the accuracy of this model is :%f&#39;%accuracy)
</pre></div></p>
<hr />
<p>update 18.12.10</p>
<blockquote>
<p>在阅读机器学习相关书籍时，回顾了一下knn算法，其中关于knn计算开销的问题，在《统计学习方法》一书中提到，可以采用kd树来减小计算量，附上笔记和学习感悟。</p>
</blockquote>
<h2 id="knn-kd">knn算法实现&ndash;&gt;kd树<a class="headerlink" href="#knn-kd" title="Permanent link"></a></h2>
<p><strong>最简单的方法是线性扫描，但计算量会随训练集增大开销增大。</strong></p>
<p>所以可以用<code>kd-tree</code>来提高效率，减少计算距离的次数。</p>
<blockquote>
<p>首先来学习一下树结构&mdash;&gt;<code>二叉查找树</code>定义:每棵二叉查找树都是一棵二叉树，每个结点有一个comparable键，每个结点的键都大于左子树任意结点的键，小于右子树任意结点的键。-----<em>《算法》</em></p>
</blockquote>
<h3 id="kd">构造kd树<a class="headerlink" href="#kd" title="Permanent link"></a></h3>
<p>平衡kd树：</p>
<ul>
<li>1.根结点&ndash;&gt;找x^(1) 的特征坐标中位数作为切分点，将区域分成2个子区域，过x^(i),垂直坐标轴；</li>
<li>2.由根结点生成深度为1的左右子节点；left &lt; x^(i),right &gt; x^(i),保存实例点在根结点中;</li>
<li>3.递归</li>
<li>4.直到两个子区域没有实例停止</li>
</ul>
<p><img alt="构造kd树" src="https://upload-images.jianshu.io/upload_images/14359324-ed42a2866e76c2fc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<blockquote>
<p>文字可能比较难理解，但是结合这个例题，可以轻松了解。</p>
<blockquote>
<p>首先将这个数据集T，<code>T是一个6行2列的数组</code>，按照特征顺序，比如第一个特征，即T中的第一列，<code>取出[2,5,9,4,8,7]</code>，按中位数7，排序，类似于二分查找，7左边的数字都要小于7，7右边的数字要大于7,于是数据集被分成2个子集；</p>
<p>接下来对两个子集继续用上述的方法递归即可(<code>用第二个特征进行递归,以此类推</code>)</p>
</blockquote>
</blockquote>
<p><img alt="kd树结构" src="https://upload-images.jianshu.io/upload_images/14359324-df02ebde44b7fdb7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<h3 id="kd_1">搜索kd树<a class="headerlink" href="#kd_1" title="Permanent link"></a></h3>
<p>目标点x；kd树</p>
<ul>
<li>找出包含x的叶结点&ndash;&gt;从根结点出发，递归访问kd树，目标节点当前维的坐标小于切分点的坐标，左移；否则右移，直到子结点是终点。</li>
<li>把该结点作为&rsquo;当前最近点&rsquo;</li>
<li>递归向上退回，对每个结点如下操作:</li>
<li>a)结点实例点比当前最近点与目标点更近，则该点为当前最近点</li>
<li>b)查找同一结点下另一子节点中的实例点，是否画圆可以相交，可以则将其作为&rsquo;当前最近点&rsquo;重新定义半径，继续递归；不相交退回到上一结点。</li>
<li>当退回到根结点时，结束搜索</li>
</ul>
<p><img alt="kd树搜索" src="https://upload-images.jianshu.io/upload_images/14359324-7dc71ced56b4fa20.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" /></p>
<hr />
<p><strong>update 18.12.14</strong></p>
<p>最近看到算法图解的knn部分，里面提到了另一个衡量差异，<code>余弦相似度</code>，是用空间中，两个向量间的夹角余弦值，来度量。比距离度量更注重方向上的差异。
<img alt="余弦相似度" src="https://ws4.sinaimg.cn/large/006tNbRwly1fy6e5pc24ij314a0q40y6.jpg" />
<img alt="计算公式" src="https://ws4.sinaimg.cn/large/006tNbRwly1fy6ec8b4q4j30ds04cwep.jpg" />
<img alt="举例说明" src="https://ws2.sinaimg.cn/large/006tNbRwly1fy6e5pi9bnj31580betcf.jpg" />
<img alt="适用场景" src="https://ws1.sinaimg.cn/large/006tNbRwly1fy6e5pvclpj314k0augol.jpg" /></p>
<hr />
<h1 id="_13">小结<a class="headerlink" href="#_13" title="Permanent link"></a></h1>
<p>通过2个例子的练习：约会对象分类、手写识别分类。发现knn算法存在一些问题：</p>
<ul>
<li>
<p><strong>算法核心在于计算测试样本与训练集所有样本之间的距离</strong></p>
<ul>
<li>首先对于<code>样本量的需求极大</code>，需要足够多的训练样本才能保证模型的精度；</li>
<li>其次对于大数据集<code>计算开销巨大</code>，非常耗时间；</li>
<li>第三，关于<code>k值选取</code>，需要人工调参，不同k值带来的分类结果不尽相同，同时，knn判别的<code>距离</code>也有多种，比如3个点，A,B1,B2。测试数据点离A更近，而离B更远，选择不同距离判断方式带来的分类情况不同。</li>
</ul>
</li>
<li>
<p><strong>在算法实现过程中的一些注意事项</strong></p>
<ul>
<li>数据集导入过程中，需要将其转化为数组的形式(特征向量)，便于计算机处理；</li>
<li>在<code>准备数据</code>的过程中，需要对数据进行归一化、去除异常值、填补缺失值等一系列操作，这一过程可以统称为特征工程(虽然这两个例子的数据都是干净的，无需太多处理)；</li>
<li><code>测试算法</code>过程中涉及到模型评估以及最终模型的选择，需要涉及到数据集划分、调参等工作；</li>
<li>需要熟悉<code>numpy</code>、<code>sklearn</code>等库等操作，可以极大提高工作效率减少代码量，做到有的放矢有重点的将时间花在其他重要的方面。</li>
</ul>
</li>
</ul>
<h1 id="_14">推荐阅读<a class="headerlink" href="#_14" title="Permanent link"></a></h1>
<p>1.《机器学习实战》
2.<a href="https://scikit-learn.org/stable/modules/neighbors.html#">sklearn-nearest neighbors</a>
3.《统计学习方法》</p></article></body></html>