{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 朴素贝叶斯算法(Naive Bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">前两张学习的knn和决策树分类都直接给出了答案，但是不能避免一些分类错误，本章学习的方法给出的是一个最优的类别猜测结果，并且给出概率估计值。\n",
    "\n",
    "* `朴素`一词是因为整个过程都是最原始最简单的假设<特征之间独立性假设>。\n",
    "\n",
    ">是基于贝叶斯定理和特征条件独立假设的分类方法。\n",
    "\n",
    "* 优点：数据少也可以有效，可以处理多分类问题\n",
    "* 缺点：输入数据的准备方式较为敏感"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__贝叶斯决策理论:__核心就是选择具有最高概率的决策。朴素贝叶斯就是基于贝叶斯决策理论的一种分类方法。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概率知识复习\n",
    "* 条件概率\n",
    "    - P(A|B) = P(A·B)/P(B)\n",
    "![例子](https://ws1.sinaimg.cn/large/006tNbRwly1fy5hufmoa3j31ek0jqtdy.jpg)\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例题：\n",
    "\n",
    "* P(A·B)-->在B桶中抽到白球的概率-->1/7；\n",
    "* P(B)-->B桶中有3块石头的概率-->3/7；\n",
    "* 根据公式P(A|B) = (1/7)/(3/7) = 1/3\n",
    "\n",
    "__贝叶斯准则__\n",
    "![image.png](attachment:image.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用朴素贝叶斯进行文档分类\n",
    "文档分类是机器学习的一个重要应用。可以观察文档中的词，将每个词的出现或者不出现作为一个特征，这样特征数目就等同于词汇表的词数。\n",
    "\n",
    "一般步骤：\n",
    "* 1） 收集数据\n",
    "* 2）准备数据(数值型、布尔型)\n",
    "* 3）分析数据(特征多，用直方图效果好)\n",
    "* 4）训练算法(计算不同独立特征多条件概率)\n",
    "* 5）测试算法(计算错误率)\n",
    "* 6）使用算法(一般应用于文档分类，但也无限制)\n",
    "\n",
    ">通常每个特征需要N个样本，10个特征需要N^10个样本；如果特征相互独立，那么样本数就变成1000*N\n",
    "\n",
    "`独立`：一个特征或者单词出现与它和其它单词相邻没有关系。\n",
    "    * 这个假设也是朴素贝叶斯分类中朴素一词的含义。\n",
    "    * 另一个假设是每个特征都是等重要的，即每个词是等权重的，只考虑词是否出现，不考虑出现次数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## python进行文本分类\n",
    "### 准备数据：词向量构建\n",
    "思路在于：\n",
    "* 构建一个词表，包含文本的所有词，长度是文本中不同词的数量\n",
    "* 对每一句话进行词向量化\n",
    "    - 构建一个同词表等长的0向量\n",
    "    - 判断每句话中的词在词表中是否出现，出现在0向量中相应位置记为1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the vocabulary list is :\n",
      "['to', 'how', 'not', 'dalmation', 'love', 'garbage', 'licks', 'my', 'mr', 'quit', 'so', 'I', 'steak', 'posting', 'food', 'flea', 'take', 'is', 'problems', 'park', 'stupid', 'please', 'him', 'ate', 'help', 'maybe', 'cute', 'worthless', 'has', 'dog', 'stop', 'buying']\n",
      "\n",
      "word2vect of sentence 2 is : \n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def loadDataSet():\n",
    "    '''\n",
    "    postingList: 切词后的句子\n",
    "    classVec:数据集对应的分类标签\n",
    "    '''\n",
    "    postingList = [ ['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'],\n",
    "                         ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],\n",
    "                         ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'],\n",
    "                         ['stop', 'posting', 'stupid', 'worthless', 'garbage'],\n",
    "                         ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'],\n",
    "                         ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']]\n",
    "    \n",
    "    classVec = [0,1,0,1,0,1]    #1代表侮辱性文字，0代表正常言论\n",
    "    return postingList,classVec\n",
    "\n",
    "def creatVocabList(dataset):\n",
    "    '''\n",
    "    构建词表\n",
    "    output:词表\n",
    "    '''\n",
    "    vocabSet = set([])\n",
    "    for doc in dataset:\n",
    "        vocabSet = vocabSet | set(doc) # 通过对两个集合取并，找出所有非重复的单词\n",
    "    return list(vocabSet)\n",
    "#对于这个函数，自己的思路是将所有句子用extend拼接成一个大list，然后用set来得到词表\n",
    "\n",
    "def Words2Vec(vocabSet, inputSet):\n",
    "    '''\n",
    "    vocabSet：词表\n",
    "    inputSet：输入需要向量化的句子\n",
    "    output：输出文档向量(0,1)形式\n",
    "    '''\n",
    "    return_vec = [0] * len(vocabSet) \n",
    "    # 创建与词汇表等长的列表向量\n",
    "    for word in inputSet:\n",
    "        if word in vocabSet:\n",
    "            return_vec[vocabSet.index(word)] = 1 # 出现的单词赋1\n",
    "        else: print(\"the word %s is not in list\" % word)\n",
    "    return return_vec\n",
    "\n",
    "if __name__=='__main__':\n",
    "    dataSet,labels = loadDataSet()\n",
    "    vocabSet = creatVocabList(dataSet)\n",
    "    wordVect = Words2Vec(vocabSet,dataSet[0])\n",
    "    print('the vocabulary list is :'+'\\n'+repr(vocabSet)+'\\n')\n",
    "    print('word2vect of sentence 2 is : '+'\\n'+repr(wordVect))\n",
    "    trainvec = []\n",
    "    for i in range(len(dataSet)):\n",
    "        wordVect = Words2Vec(vocabSet,dataSet[i])\n",
    "        trainvec.append(wordVect)\n",
    "    trainvec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练算法：根据词向量计算概率\n",
    "目的是：输入训练样本和标签，可以得到词表中`每个词是某一类别的概率`。即计算P(Ci|wi)的概率。比如在wi这个词出现的条件下，它是类别1的概率。后验求条件概率需要用到贝叶斯公式。\n",
    "\n",
    ">**朴素贝叶斯分类器就是基于数据集D，估计先验概率P(c)，再对每个属性，估计条件概率P(wi | c).**\n",
    "* 先验概率是属于某个类别的样本集合Dc/样本总数，是横向计算\n",
    "* 条件概率是在上述样本空间内，某个样本属性取值的集合/Dc。纵向计算\n",
    "\n",
    "![贝叶斯公式](https://ws1.sinaimg.cn/large/006tNbRwly1fy5hugaa9uj30x409a761.jpg)\n",
    "W是一个特征向量，长度和词表长度相同；c是对应的类别；P(W) = ∑P(W|ci)·P(ci)全概率公式得到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "先验概率 p(c=1) =  0.5\n",
      "每个特征的条件概率 p(w | c=1) =  [0.05263158 0.         0.05263158 0.         0.         0.05263158\n",
      " 0.         0.         0.         0.05263158 0.         0.\n",
      " 0.         0.05263158 0.05263158 0.         0.05263158 0.\n",
      " 0.         0.05263158 0.15789474 0.         0.05263158 0.\n",
      " 0.         0.05263158 0.         0.10526316 0.         0.10526316\n",
      " 0.05263158 0.05263158]\n",
      "c=1,the word with the max Probability=(0.157895), is(stupid)\n",
      "词条属于侮辱性词语的概率排序：[('stupid', 0.15789473684210525), ('worthless', 0.10526315789473684), ('dog', 0.10526315789473684), ('to', 0.05263157894736842), ('not', 0.05263157894736842)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def NaiveBayes0(trainMatrix,trainCategory):\n",
    "    '''\n",
    "    用朴素贝叶斯计算先验概率P(ci)和条件概率P(w | ci)\n",
    "    trainMatrix:特征向量组成的矩阵\n",
    "    trainCategory:各特征向量对应的分类\n",
    "    '''\n",
    "    \n",
    "    numTrain = len(trainMatrix) #训练的文档个数\n",
    "    numWords = len(trainMatrix[0]) #词表的大小，即特征的大小\n",
    "    \n",
    "    p1 = sum(trainCategory)/float(numTrain)  #分类1的概率p(y=1)，标签中1出现的次数/总文档数；p(y=0) = 1-p1\n",
    "    p0Num = np.zeros(numWords); p1Num = np.zeros(numWords)      #初始化为0\n",
    "    p0Denom = 0.0; p1Denom = 0.0 \n",
    "    \n",
    "    #对每一个训练文档\n",
    "    for i in range(numTrain):\n",
    "        \n",
    "        #出现侮辱性词语\n",
    "        if trainCategory[i] == 1:\n",
    "            p1Num += trainMatrix[i] \n",
    "            #c=1条件下，统计某个单词出现的个数(因为每个特征向量都是等长的，其中每个词条位置固定，可以直接相加来计算次数)，用于计算p(wi/c=1)\n",
    "            p1Denom += sum(trainMatrix[i]) \n",
    "            #累计c=1的所有单词数量\n",
    "        else:\n",
    "            p0Num += trainMatrix[i] \n",
    "            p0Denom += sum(trainMatrix[i]) \n",
    "            \n",
    "    p1Vect = p1Num/float(p1Denom)     #p(w/c=1)   \n",
    "    p0Vect = p0Num/float(p0Denom)     #p(w/c=0)  \n",
    "    \n",
    "    return p0Vect,p1Vect,p1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    p0Vect,p1Vect,p1 = NaiveBayes0(trainvec,labels)\n",
    "    print(\"先验概率 p(c=1) = \",p1)  #classVec = [0,1,0,1,0,1] ,so p1=0.5\n",
    "    print(\"每个特征的条件概率 p(w | c=1) = \",p1Vect)\n",
    "    print(\"c=1,the word with the max Probability=(%f), is(%s)\"%(np.max(p1Vect),vocabSet[np.argmax(p1Vect)]))\n",
    "    # 对词条按概率排序\n",
    "    dt = list(p1Vect)\n",
    "    result = dict(list(zip(vocabSet,dt)))\n",
    "    result_sort = sorted(result.items(),key=lambda x:x[1],reverse=True)[0:5]\n",
    "    print('词条属于侮辱性词语的概率排序：'+repr(result_sort))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">这个结果表示，在侮辱性的类别中，词条stupid一词是出现频率最高的词，即这个词是侮辱性词语的概率最大。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 在计算多个概率乘积会因为某个概率值为0，导致乘积也为0，可以初始化所有词为1，分母初始化为2。\n",
    "* 小数相乘会出现下溢现象，即四舍五入的时候会变成0，需要取log\n",
    "\n",
    ">统计学习方法里面提到，原来的估计方法是极大似然估计，可以用贝叶斯估计来优化，具体做法如下图：\n",
    "![拉普拉斯平滑](https://ws3.sinaimg.cn/large/006tNbRwly1fy5hyizrs5j30q006udgq.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaiveBayes1(trainMatrix,trainCategory):\n",
    "    numTrain = len(trainMatrix) #训练的文档个数\n",
    "    numWords = len(trainMatrix[0]) #词汇表的大小，即特征的大小\n",
    "    p1 = sum(trainCategory)/float(numTrain)  #分类1的概率p(y=1)，这里是二分类，所以，p0=1-p1\n",
    "    p0Num = np.ones(numWords); p1Num = np.ones(numWords)      #change to 1 ,一般sigma = 1\n",
    "    p0Denom = 2.0; p1Denom = 2.0                        # change to 2.0 因为有两个类别\n",
    "    for i in range(numTrain):\n",
    "        if trainCategory[i] == 1:\n",
    "            p1Num += trainMatrix[i] #y=1条件下，统计某个单词出现的个数，用于计算p(w/y=1)\n",
    "            p1Denom += sum(trainMatrix[i]) #累计y=1的所有单词数量\n",
    "        else:\n",
    "            p0Num += trainMatrix[i] #y=0条件下，统计某个单词出现的个数，用于计算p(w/y=0)\n",
    "            p0Denom += sum(trainMatrix[i]) #累计y=0的所有单词数量\n",
    "    p1Vect = np.log(p1Num/float(p1Denom))         #change to log()\n",
    "    p0Vect = np.log(p0Num/float(p0Denom))          #change to log()\n",
    "    return p0Vect,p1Vect,p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-2.56494936, -2.56494936, -3.25809654, -2.56494936, -2.56494936,\n",
       "        -3.25809654, -2.56494936, -1.87180218, -2.56494936, -3.25809654,\n",
       "        -2.56494936, -2.56494936, -2.56494936, -3.25809654, -3.25809654,\n",
       "        -2.56494936, -3.25809654, -2.56494936, -2.56494936, -3.25809654,\n",
       "        -3.25809654, -2.56494936, -2.15948425, -2.56494936, -2.56494936,\n",
       "        -3.25809654, -2.56494936, -3.25809654, -2.56494936, -2.56494936,\n",
       "        -2.56494936, -3.25809654]),\n",
       " array([-2.35137526, -3.04452244, -2.35137526, -3.04452244, -3.04452244,\n",
       "        -2.35137526, -3.04452244, -3.04452244, -3.04452244, -2.35137526,\n",
       "        -3.04452244, -3.04452244, -3.04452244, -2.35137526, -2.35137526,\n",
       "        -3.04452244, -2.35137526, -3.04452244, -3.04452244, -2.35137526,\n",
       "        -1.65822808, -3.04452244, -2.35137526, -3.04452244, -3.04452244,\n",
       "        -2.35137526, -3.04452244, -1.94591015, -3.04452244, -1.94591015,\n",
       "        -2.35137526, -2.35137526]),\n",
       " 0.5)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NaiveBayes1(trainvec,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取log自然就是负值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[关于朴素贝叶斯算法推导](https://www.cnblogs.com/liuwu265/p/4685361.html)\n",
    "\n",
    "李航书中关于朴素贝叶斯分类器在最后部分，分母问题上不是很清楚，这篇文章帮助我理解，为什么分母可以约去，只考虑分子部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(testVec, p0Vec, p1Vec, pClass1):\n",
    "    '''\n",
    "    朴素贝叶斯分类器-->用于计算特征的类别\n",
    "    testVec:特征向量(测试样本)\n",
    "    p0Vect:P(w | c=0)条件概率\n",
    "    p1Vect:P(w | c =1)条件概率\n",
    "    pClass1:P(c = i)先验概率\n",
    "    output:返回分类的结果1:侮辱性，0:非侮辱性。\n",
    "    '''\n",
    "    p1 = sum(testVec * p1Vec) + np.log(pClass1)    #因为是log,ln(a*b) = ln(a)+ln(b)所以这里是求和以及+号操作\n",
    "    #p(c=1/w) = p(w/c=1) * p(c=1)因为根据朴素贝叶斯算法公式，分母是P(C = Ci),分母对于已知的，对估计结果不影响，可以约去；至于乘上testVec,不是很清楚。\n",
    "    \n",
    "    p0 = sum(testVec * p0Vec) + np.log(1.0 - pClass1) #p(y=0) = 1 - p(y=1)\n",
    "    if p1 > p0: #选取最大的概率的类\n",
    "        return 1\n",
    "    else: \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['love', 'my', 'dalmation'] classified as:  0\n",
      "['stupid', 'garbage'] classified as:  1\n"
     ]
    }
   ],
   "source": [
    "p0V,p1V,p1 = NaiveBayes1(trainvec,labels)\n",
    "test0 = ['love', 'my', 'dalmation']\n",
    "testVec0 = Words2Vec(vocabSet, test0)\n",
    "print(test0,'classified as: ',classify(testVec0,p0V,p1V,p1))\n",
    "test1 = ['stupid', 'garbage']\n",
    "testVec1 = Words2Vec(vocabSet, test1)\n",
    "print(test1,'classified as: ',classify(testVec1,p0V,p1V,p1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 词袋模型(bag of words model)\n",
    "* 对于每个词是否出现---->词集模型(`set of words model`)\n",
    "* 对于每个词可以多次出现--->词袋模型(`bag of words model`)\n",
    "\n",
    "因此需要对词向量模型做一些修改\n",
    "* 每当遇到一个单词，模型会增加词向量中对应的值，而不是全为1.\n",
    "\n",
    "idea:\n",
    "* 构建一个长度同词表的0向量\n",
    "* 对样本中每个词遍历:\n",
    "    - 判断该词是否在词表中:\n",
    "        - 在,则在0向量相应位置记1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagOfWordsVec(vocabSet, inputSet):\n",
    "    '''\n",
    "    词袋模型，需要统计某个词条出现的次数\n",
    "    vocabSet:词表\n",
    "    inputSet:一个样本；特征向量\n",
    "    output:词向量\n",
    "    '''\n",
    "    returnVec = [0]*len(vocabSet)\n",
    "    for word in inputSet:\n",
    "        if word in vocabSet:\n",
    "            returnVec[vocabSet.index(word)] += 1 #出现一次，累加一次\n",
    "    return returnVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词袋模型的词向量:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "test_Vec = bagOfWordsVec(vocabSet,['i','hate','this','stupid','dog'])\n",
    "print('词袋模型的词向量:'+repr(test_Vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 练习-用朴素贝叶斯分类器过滤垃圾邮件\n",
    "__步骤依然是：__\n",
    "* 收集数据\n",
    "* 准备数据-->文件文本向量化\n",
    "* 分析数据\n",
    "* 训练算法-->训练模型\n",
    "* 测试算法-->查看文档分类的错误率\n",
    "* 使用算法-->构建完整程序，并将分类结果以及错误分类情况输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">数据包含已经分类的普通邮件和垃圾邮件各25封,需要做的是将数据集划分成训练集和测试集；将划分好的数据集进行词向量化；将词向量给分类器进行分类；根据标签集统计分类错误率；由于划分数据集是随机的，需要重复多次取均值。\n",
    "\n",
    "idea:\n",
    "* 划分数据集，随机采样-->书上是4:1\n",
    "* 词向量化\n",
    "* 训练\n",
    "* 计算错误率\n",
    "* 重新划分数据集(重复)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__准备数据__\n",
    "* 读取文本数据，预处理，只保留文本(需要用到正则表达式)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def textParse(bigString):\n",
    "    '''\n",
    "    字符串处理函数：保留英文字符和数字作为词条，且长度>2\n",
    "    bigString:输入的文本文件\n",
    "    output:返回一个词列表\n",
    "    '''\n",
    "    listOfTokens = re.split(r'\\W*', bigString) #只需要字符和数字\n",
    "    return [tok.lower() for tok in listOfTokens if len(tok) > 2] #变成小写，过滤长度小于3的字符串 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spamTest():\n",
    "    '''\n",
    "    垃圾邮件分类函数\n",
    "    '''\n",
    "    docList=[]; classList = []; fullText =[]\n",
    "    #分别是总邮件列表，邮件对应分类标签集合，所有句子组成的文本\n",
    "    for i in list(range(1,26)): #每个文件夹，有25个文件\n",
    "        wordList = textParse(open('./email/spam/%d.txt' % i,encoding='ISO-8859-1').read())\n",
    "        docList.append(wordList)\n",
    "        fullText.extend(wordList)\n",
    "        classList.append(1)\n",
    "        wordList = textParse(open('./email/ham/%d.txt' % i,encoding='ISO-8859-1').read())\n",
    "        docList.append(wordList)\n",
    "        fullText.extend(wordList)\n",
    "        classList.append(0)\n",
    "    \n",
    "    vocabularyList = creatVocabList(docList)#建总词表\n",
    "    trainingSet =list( range(50)); testSet=[]   #create test set,这里其实是val set，而且只保存了下标\n",
    "    for i in list(range(10)):\n",
    "        randIndex = int(np.random.uniform(0,len(trainingSet)))\n",
    "        testSet.append(trainingSet[randIndex])\n",
    "        del(trainingSet[randIndex])  #随机选取10个，并且从train中删除\n",
    "    '''\n",
    "    抽样将数据集一开始合并成同一个数组比较好，将分类标签全部加在list[0]位置，或者把数据集append方法加在标签集后面便于后续操作。\n",
    "    抽样可方法很多，无非是记住index，然后从数据集中选择，自己选用的是random.sample()函数，从1-50数组中抽样得到index_list，然后划分。\n",
    "    其中用了map(),和filter()方法,可读性更强。\n",
    "    '''  \n",
    "    trainMat=[]; trainClasses = []\n",
    "    for docIndex in trainingSet:#获得索引\n",
    "        trainMat.append(bagOfWordsVec(vocabularyList, docList[docIndex]))\n",
    "        trainClasses.append(classList[docIndex])\n",
    "    p0V,p1V,pSpam = NaiveBayes1(trainMat,trainClasses) #训练，得到条件概率\n",
    "    errorCount = 0\n",
    "    for docIndex in testSet:        #classify the remaining items\n",
    "        wordVector = bagOfWordsVec(vocabularyList, docList[docIndex])\n",
    "        if classify(wordVector,p0V,p1V,pSpam) != classList[docIndex]: #用于test/val\n",
    "            errorCount += 1\n",
    "            #print( \"classification error\",docList[docIndex])\n",
    "    #print('the error rate is: ',float(errorCount)/len(testSet))\n",
    "    return float(errorCount)/len(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tony/anaconda3/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spamTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 留出法\n",
    "由于随机划分数据集是随机的，单次划分结果不够稳定，需要多次重复取均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tony/anaconda3/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20次重复划分数据集的平均误差：0.050000\n"
     ]
    }
   ],
   "source": [
    "Er = []\n",
    "for i in range(20):\n",
    "    error = spamTest()\n",
    "    Er.extend([error])\n",
    "mean_error = sum(Er)/20\n",
    "print('20次重复划分数据集的平均误差：%f'%mean_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__关于抽样的一些想法和实现__\n",
    "* 1.用random.sample()对数组抽样，得到训练集index\n",
    "* 2.用map(),从未划分的数据集中，按index索引取样\n",
    "* 3.用filter(),得到测试集的index\n",
    "* 4.同2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def splitDataSet(docList,classList,size):\n",
    "    '''\n",
    "    随机抽样-数据集划分\n",
    "    docList:未划分的训练集\n",
    "    classList:未划分的标签集\n",
    "    sample:采样大小\n",
    "    output:划分后的训练集、测试集及其对应的分类标签\n",
    "    '''\n",
    "    import random\n",
    "    #训练集\n",
    "    index_train = random.sample(range(50),size)\n",
    "    trainSet = list(map(lambda x:docList[x],index_train))\n",
    "    classSet_train = list(map(lambda x:classList[x],index_train))\n",
    "    #测试集\n",
    "    index_test = list(filter(lambda x:x not in index_train,range(50)))\n",
    "    testSet = list(map(lambda x:docList[x],index_test))\n",
    "    classSet_test = list(map(lambda x:classList[x],index_test))\n",
    "    return trainSet,classSet_train,testSet,classSet_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain,labeltrain,dtest,labeltest = splitDataSet(docList,classList,40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小结\n",
    "关于朴素贝叶斯算法，核心在于通过朴素贝叶斯公式和‘朴素’这个特点，即通过假设随机变量之间两两独立，从而简化了特征之间的关系，利用先验概率和条件概率，来估算后验概率，选择后验概率中的最大概率，来确定最终的类别。\n",
    ">主要有以下几个注意点：\n",
    "* `词向量化(word2Vector)`：主要是通过构造词表，即将切词后的所有文本组成一个集合，组成一个n维的词向量，每个词在相应的位置，出现记1，不出现记0。\n",
    "* `词集模型(set of words model)`:就是将词是否出现作为判断依据，只考虑是否出现，而不考虑出现的次数。\n",
    "* `词袋模型(bag of words model)`:将词出现的次数考虑在内，来生成词向量。\n",
    "* `朴素`的含义：对条件概率做了独立性假设，假设各特征属性之间相互独立。\n",
    "* 对于`后验概率最大化`，李航书中解释是等价于`期望风险最小化`，具体可以看推导过程。\n",
    "* 由于用朴素贝叶斯法的参数估计采用的是`极大似然估计`，可能会出现特征属性集合为0而导致估计的概率乘积为0，导致结果出现偏差，需要用到贝叶斯估计来修正，通常在随机变量各取值频数上加一个正数λ，=0是极大似然估计，=1是`拉普拉斯平滑`，通常分子是λ，分母是Kλ,K表示分类类别数量。\n",
    "* `下溢问题`(太小的数相乘导致取值近似为0)可以用取对数来解决，要降低错误率可以通过去停用词等方法改进。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
